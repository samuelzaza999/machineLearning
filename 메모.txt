(지능, intelligence , 知能)
현상을 이해하고 대처 방법을 알아내는
지적 활동 능력

AI (Artificial Intelligence),
그러한 지능을 사람이
컴퓨터에 구현한 것

4차 산업 혁명:
SNS, 빅데이터, 사물인터넷,
클라우드 컴퓨팅, 가상현실(VR),
증강현실(AR), 3D 프린팅, 로봇,
자율주행차, 드론, 바이오·나노
기술, 소재과학, 유전자가위,
양자컴퓨터, 블록체인, 인공지능
등의 첨단기술들이 발전·융합
범용 플랫폼, 모든 곳에 활용가능
제품과 서비스의 지능화(AI)

도전의 중요성 : 두려움?

흐름

------------------------------
https://www.kaggle.com/yungbyun

머신러닝 : 기계의 알고리즘, 데이터로 구현
딥러닝 : 뇌의 알고리즘

-----------
캐글 실습 : 깃허브 - 성별 인식 코드
세션 켜고 Run All


머신러닝 ::
구구단처럼 문제와 정답을 학습, 중간에 잘라 학습과 테스트 데이터 분리
-> 학습은 다 확인하고 테스트는 풀게 해 정답과 대조
ex) 키, 무게, 발크기, 학년 -> 성별

aaa = svm.SVC()
aaa.fit('학습용 문제', '정답')
prediction = aaa.predict('테스트용 문제')

어느 방식이든 객체가 받는 클래스만 바뀌고 적용하는 방법은 위와 동일.

서포트 벡터 머신(SVC) : 분류에서 결정적 도움 주는 인접 자료.

데이터 읽어오기
-> 시각화하기
-> 학습용/테스트용 나누기
-> 머신러닝 모델 학습시키기
-> 테스트하기(예측, 분류)

166,57,240,1, 0
178,92,265,1, 1
167,80,270,1, 1
168,52,245,2, 1
155,60,235,2, 0
163,45,230,2, 0
160,53,235,3, 0
180,77,260,4, 1
167,71,260,2, 1
160,51,245,2, 0
162,53,240,2, 0
180,82,280,6, 1
172,90,255,6, 1
160,51,245,5, 0

155,66,245,5, 0
163,54,242,5, 0
177,88,263,5, 1
166,82,268,6, 1
170,53,247,6, 1
154,59,234,1, 0
164,47,232,1, 0

인공지능 : 별도 데이터 없이 구현 가능
머신러닝 : 데이터를 주고 학습

해쉬 함수 :
한 방향으로 데이터 변조하면 복구 불가. 블록체인 -> 데이터와 해쉬 비교해 변조 확인
해쉬 작업의 대가로 랜덤하게 코인 생성(채굴)

엔진 이전에 운전부터.
모듈화 자주하고 파라미터만 돌려막기로 능률 향상

파이썬 '필드 column' 줘서 모듈화한 식에 때려박기 -> 일반적인 사용 가능

---------------- 0322
데이터 읽어오기
-> 표시하기
-> 학습용/테스트용 나누기
-> 머신러닝 모델 학습시키기
-> 테스트하기(예측, 분류)
 = 읽 표 나 학 테

gil = DecisionTreeClassifier()
gil.fit('학습용 문제', '정답')
prediction = gil.predict('테스트용 문제')


>>> Female/Male Classification_ML_Simple

읽기 >
csv 파일 읽기 :
import pandas as pd
data = pd.read_csv("asdf.csv")

표시 >
점 찍기 :
plot(data, "Height", "Weight", "Sex")
바이올린 형태 분포도 :
violinplot(data, "Height", "Sex")

나누기 >
학습용 80%, 테스트용 20%로 데이터 나누기 :
train, test = split(data, 0.8)
학습 입력 & 정답 :
train_x = train[['Height', 'FeetSize', 'Weight']]
train_y = train.Sex
테스트 입력 & 정답 :
test_x = test[['Height', 'FeetSize', 'Weight']]
test_y = test.Sex

---------------- 0323
학습 >
정답 5개 호출 :
test_x.head(5)
학습시키기 & 예측하기 :
from sklearn import svm
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
gil = svm.SVC()
gil.fit(train_x, train_y)
prediction = gil.predict(test_x)

테스트 >
print('인식률 : ', metrics.accuracy_score(prediction, test_y) * 100)
gil = LogisticRegression()
gil = KNeighborsClassifier(n_neighbors = 3)


>>> plant_diary_original_simple

데이터 처리 모듈 :
import pandas as pd
테이터 시각화 모듈 :
import matplotlib.pyplot as plt
import seaborn as sns
데이터 분할 모듈 :
from sklearn.model_selection import train_test_split

from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor

나누기 >
train, test = split(data, 0.8)
train_x = train[['day']]
train_y = train.height
test_x = test[['day']]
test_y = test.height

학습(4가지) >
취사선택 :
gil = LinearRegression()
gil = KNeighborsRegressor(n_neighbors = 2)
gil = RandomForestRegressor(n_estimators = 28, random_state = 0)
gil = DecisionTreeRegressor(random_state = 0)LinearRegression()
이후 공통 사항 :
gil.fit(train_x, train_y)
score = gil.score(test_x, test_y)
print('score : ', format(score, '.3f'))

테스트 >
prediction = gil.predict(test_x)
print('예상 : ', prediction)
print('정답 : ', test_y)


★머신러닝의 핵심 ::
종류 이거 or 저거? : 분류
-> 비가 올까 안 올까, 더울까 추울까, 학년이 어떻게 될까
값이 얼만큼 될까? : 예측
-> 몸무게가 어떻게 될까, 내일 온도는 어떨까


머신러닝 중에서 사람의 뇌를 모방 : 딥러닝.

-------------- 0329
딥러닝 :: 시냅스(연결부위, 신경망)의 구현.
★시냅스에서 신경전달물질(단백질)이 수용체로 이동, 물질이 많이 나올 수록 전달되는 전기신호가 강해진다.
뇌는 신호가 발생 or X로만 구분.
신호 * 신경전달물질의 양 = 전기신호 -> 특정 레벨 이상일 때만 발생 판정 -> 신경세포 핵에서 전기신호 합치기
신경전달물질의 설정에 따라 전기신호가 다르게 발생. 걷는 용도, 기억하는 용도 등

---------------- 0330
신호 -> 신경전달물질 -> 물질이 수용체로 이동 -> 반대편 뉴런 자극 -> 신경전달물질을 원래 자리 회수 -> 반복

뇌 문제 :
시냅스 작동 X -> 마비, 치매 등
= 시냅스 설정 X, 신경전달물질의 양 제대로 설정 X
-> 딥러닝은 신경전달물질의 양을 바꾸는 프로그래밍.

습관 바꾸기? :
부정적 이미지 심기. 고통 주입. -> 신경전달물질의 양 변화로 기억하기.
= 뇌내 학습의 원리? : 행복은 늘리고 고통은 줄이는 방향으로.

그림책 : 입력을 주고 정답을 알려준다. -> 학습으로 신경전달물질 설정하기.
gil.fit(<그림>, '오리')


뉴런의 동작(출력) ::
신경세포가 단 하나라 가정. (w=1)
신경세포 출력 h = 입력 x * 연결강도(신경전달물질 양 : 단절/약/강) w
w=1인 뉴런 : h = 1x

★학습이란? :
신경전달물질의 양(w)을 조절하는 것.

ex)
1시간(x) 공부하면 1시간(ground truth) 게임.
그럼 4시간 공부에 몇 시간 게임할 수 있을지(prediction) w값 구하기.
h = w * x(=1)
입력과 정답이 정해졌다면 강도의 변화에 따라 오차를 찾아내(야단) 줄여나간다.

실제로는 여러 개의 입력. 입력의 수만큼 연결도 존재.
-> 각 입력마다 시냅스의 가중치를 곱한 뒤 모두 더한다. (weighted sum)

뉴런은 weighted sum이 일정 값 이상일 때만 신호 발생. (계단 함수)
= 특정 값(T) 이상이면 ON(1), 아니면 OFF(0)
신경세포 핵에서 weighted sum & 계단 함수 역할.

★시험 : 뉴런 그리기.
h = 1x
h = x1 + 2x2 + x3 + 3x4
h = 1 (if x1 + 2x2 + x3 + 3x4 > T) / 0 (otherwise)

-------------- 0405
아기가 불을 만져도 떼지 못하는 이유?
: 시냅스가 설정되지 않아서 뉴런 간에 고통 -> 회피 구성이 없음.
뉴런의 출력 = 대답.

[선형회귀]
회귀(regression) :
자연의 법칙, 현상. 그에 따른 예측이 가능.
ex) 연어, 연령과 힘의 관계

선형회귀 :
비례 관계의 회귀. 선형회귀를 모아서 비선형 예측 가능.
-> 회귀 형태가 비선형이어도 선형회귀라 할 수 있다.
ex) 집의 크기-가격의 직선 그래프
x가 어떠한 선형결합 상태인지.
y축(가격) : 뉴런이 맞춰야 할 정답, 그를 결정하는 팩터들이 많다. 학군, 혐오시설...