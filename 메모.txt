(ì§€ëŠ¥, intelligence , çŸ¥èƒ½)
í˜„ìƒì„ ì´í•´í•˜ê³  ëŒ€ì²˜ ë°©ë²•ì„ ì•Œì•„ë‚´ëŠ”
ì§€ì  í™œë™ ëŠ¥ë ¥

AI (Artificial Intelligence),
ê·¸ëŸ¬í•œ ì§€ëŠ¥ì„ ì‚¬ëŒì´
ì»´í“¨í„°ì— êµ¬í˜„í•œ ê²ƒ

4ì°¨ ì‚°ì—… í˜ëª…:
SNS, ë¹…ë°ì´í„°, ì‚¬ë¬¼ì¸í„°ë„·,
í´ë¼ìš°ë“œ ì»´í“¨íŒ…, ê°€ìƒí˜„ì‹¤(VR),
ì¦ê°•í˜„ì‹¤(AR), 3D í”„ë¦°íŒ…, ë¡œë´‡,
ììœ¨ì£¼í–‰ì°¨, ë“œë¡ , ë°”ì´ì˜¤Â·ë‚˜ë…¸
ê¸°ìˆ , ì†Œì¬ê³¼í•™, ìœ ì „ìê°€ìœ„,
ì–‘ìì»´í“¨í„°, ë¸”ë¡ì²´ì¸, ì¸ê³µì§€ëŠ¥
ë“±ì˜ ì²¨ë‹¨ê¸°ìˆ ë“¤ì´ ë°œì „Â·ìœµí•©
ë²”ìš© í”Œë«í¼, ëª¨ë“  ê³³ì— í™œìš©ê°€ëŠ¥
ì œí’ˆê³¼ ì„œë¹„ìŠ¤ì˜ ì§€ëŠ¥í™”(AI)

ë„ì „ì˜ ì¤‘ìš”ì„± : ë‘ë ¤ì›€?

íë¦„

------------------------------
https://www.kaggle.com/yungbyun

ë¨¸ì‹ ëŸ¬ë‹ : ê¸°ê³„ì˜ ì•Œê³ ë¦¬ì¦˜, ë°ì´í„°ë¡œ êµ¬í˜„
ë”¥ëŸ¬ë‹ : ë‡Œì˜ ì•Œê³ ë¦¬ì¦˜

-----------
ìºê¸€ ì‹¤ìŠµ : ê¹ƒí—ˆë¸Œ - ì„±ë³„ ì¸ì‹ ì½”ë“œ
ì„¸ì…˜ ì¼œê³  Run All


ë¨¸ì‹ ëŸ¬ë‹ ::
êµ¬êµ¬ë‹¨ì²˜ëŸ¼ ë¬¸ì œì™€ ì •ë‹µì„ í•™ìŠµ, ì¤‘ê°„ì— ì˜ë¼ í•™ìŠµê³¼ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬
-> í•™ìŠµì€ ë‹¤ í™•ì¸í•˜ê³  í…ŒìŠ¤íŠ¸ëŠ” í’€ê²Œ í•´ ì •ë‹µê³¼ ëŒ€ì¡°
ex) í‚¤, ë¬´ê²Œ, ë°œí¬ê¸°, í•™ë…„ -> ì„±ë³„

aaa = svm.SVC()
aaa.fit('í•™ìŠµìš© ë¬¸ì œ', 'ì •ë‹µ')
prediction = aaa.predict('í…ŒìŠ¤íŠ¸ìš© ë¬¸ì œ')

ì–´ëŠ ë°©ì‹ì´ë“  ê°ì²´ê°€ ë°›ëŠ” í´ë˜ìŠ¤ë§Œ ë°”ë€Œê³  ì ìš©í•˜ëŠ” ë°©ë²•ì€ ìœ„ì™€ ë™ì¼.

ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹ (SVC) : ë¶„ë¥˜ì—ì„œ ê²°ì •ì  ë„ì›€ ì£¼ëŠ” ì¸ì ‘ ìë£Œ.

ë°ì´í„° ì½ì–´ì˜¤ê¸°
-> ì‹œê°í™”í•˜ê¸°
-> í•™ìŠµìš©/í…ŒìŠ¤íŠ¸ìš© ë‚˜ëˆ„ê¸°
-> ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµì‹œí‚¤ê¸°
-> í…ŒìŠ¤íŠ¸í•˜ê¸°(ì˜ˆì¸¡, ë¶„ë¥˜)

166,57,240,1, 0
178,92,265,1, 1
167,80,270,1, 1
168,52,245,2, 1
155,60,235,2, 0
163,45,230,2, 0
160,53,235,3, 0
180,77,260,4, 1
167,71,260,2, 1
160,51,245,2, 0
162,53,240,2, 0
180,82,280,6, 1
172,90,255,6, 1
160,51,245,5, 0

155,66,245,5, 0
163,54,242,5, 0
177,88,263,5, 1
166,82,268,6, 1
170,53,247,6, 1
154,59,234,1, 0
164,47,232,1, 0

ì¸ê³µì§€ëŠ¥ : ë³„ë„ ë°ì´í„° ì—†ì´ êµ¬í˜„ ê°€ëŠ¥
ë¨¸ì‹ ëŸ¬ë‹ : ë°ì´í„°ë¥¼ ì£¼ê³  í•™ìŠµ

í•´ì‰¬ í•¨ìˆ˜ :
í•œ ë°©í–¥ìœ¼ë¡œ ë°ì´í„° ë³€ì¡°í•˜ë©´ ë³µêµ¬ ë¶ˆê°€. ë¸”ë¡ì²´ì¸ -> ë°ì´í„°ì™€ í•´ì‰¬ ë¹„êµí•´ ë³€ì¡° í™•ì¸
í•´ì‰¬ ì‘ì—…ì˜ ëŒ€ê°€ë¡œ ëœë¤í•˜ê²Œ ì½”ì¸ ìƒì„±(ì±„êµ´)

ì—”ì§„ ì´ì „ì— ìš´ì „ë¶€í„°.
ëª¨ë“ˆí™” ìì£¼í•˜ê³  íŒŒë¼ë¯¸í„°ë§Œ ëŒë ¤ë§‰ê¸°ë¡œ ëŠ¥ë¥  í–¥ìƒ

íŒŒì´ì¬ 'í•„ë“œ column' ì¤˜ì„œ ëª¨ë“ˆí™”í•œ ì‹ì— ë•Œë ¤ë°•ê¸° -> ì¼ë°˜ì ì¸ ì‚¬ìš© ê°€ëŠ¥

---------------- 0322
ë°ì´í„° ì½ì–´ì˜¤ê¸°
-> í‘œì‹œí•˜ê¸°
-> í•™ìŠµìš©/í…ŒìŠ¤íŠ¸ìš© ë‚˜ëˆ„ê¸°
-> ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµì‹œí‚¤ê¸°
-> í…ŒìŠ¤íŠ¸í•˜ê¸°(ì˜ˆì¸¡, ë¶„ë¥˜)
 = ì½ í‘œ ë‚˜ í•™ í…Œ

gil = DecisionTreeClassifier()
gil.fit('í•™ìŠµìš© ë¬¸ì œ', 'ì •ë‹µ')
prediction = gil.predict('í…ŒìŠ¤íŠ¸ìš© ë¬¸ì œ')


>>> Female/Male Classification_ML_Simple

ì½ê¸° >
csv íŒŒì¼ ì½ê¸° :
import pandas as pd
data = pd.read_csv("asdf.csv")

í‘œì‹œ >
ì  ì°ê¸° :
plot(data, "Height", "Weight", "Sex")
ë°”ì´ì˜¬ë¦° í˜•íƒœ ë¶„í¬ë„ :
violinplot(data, "Height", "Sex")

ë‚˜ëˆ„ê¸° >
í•™ìŠµìš© 80%, í…ŒìŠ¤íŠ¸ìš© 20%ë¡œ ë°ì´í„° ë‚˜ëˆ„ê¸° :
train, test = split(data, 0.8)
í•™ìŠµ ì…ë ¥ & ì •ë‹µ :
train_x = train[['Height', 'FeetSize', 'Weight']]
train_y = train.Sex
í…ŒìŠ¤íŠ¸ ì…ë ¥ & ì •ë‹µ :
test_x = test[['Height', 'FeetSize', 'Weight']]
test_y = test.Sex

---------------- 0323
í•™ìŠµ >
ì •ë‹µ 5ê°œ í˜¸ì¶œ :
test_x.head(5)
í•™ìŠµì‹œí‚¤ê¸° & ì˜ˆì¸¡í•˜ê¸° :
from sklearn import svm
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
gil = svm.SVC()
gil.fit(train_x, train_y)
prediction = gil.predict(test_x)

í…ŒìŠ¤íŠ¸ >
print('ì¸ì‹ë¥  : ', metrics.accuracy_score(prediction, test_y) * 100)
gil = LogisticRegression()
gil = KNeighborsClassifier(n_neighbors = 3)


>>> plant_diary_original_simple

ë°ì´í„° ì²˜ë¦¬ ëª¨ë“ˆ :
import pandas as pd
í…Œì´í„° ì‹œê°í™” ëª¨ë“ˆ :
import matplotlib.pyplot as plt
import seaborn as sns
ë°ì´í„° ë¶„í•  ëª¨ë“ˆ :
from sklearn.model_selection import train_test_split

from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor

ë‚˜ëˆ„ê¸° >
train, test = split(data, 0.8)
train_x = train[['day']]
train_y = train.height
test_x = test[['day']]
test_y = test.height

í•™ìŠµ(4ê°€ì§€) >
ì·¨ì‚¬ì„ íƒ :
gil = LinearRegression()
gil = KNeighborsRegressor(n_neighbors = 2)
gil = RandomForestRegressor(n_estimators = 28, random_state = 0)
gil = DecisionTreeRegressor(random_state = 0)LinearRegression()
ì´í›„ ê³µí†µ ì‚¬í•­ :
gil.fit(train_x, train_y)
score = gil.score(test_x, test_y)
print('score : ', format(score, '.3f'))

í…ŒìŠ¤íŠ¸ >
prediction = gil.predict(test_x)
print('ì˜ˆìƒ : ', prediction)
print('ì •ë‹µ : ', test_y)


â˜…ë¨¸ì‹ ëŸ¬ë‹ì˜ í•µì‹¬ ::
ì¢…ë¥˜ ì´ê±° or ì €ê±°? : ë¶„ë¥˜
-> ë¹„ê°€ ì˜¬ê¹Œ ì•ˆ ì˜¬ê¹Œ, ë”ìš¸ê¹Œ ì¶”ìš¸ê¹Œ, í•™ë…„ì´ ì–´ë–»ê²Œ ë ê¹Œ
ê°’ì´ ì–¼ë§Œí¼ ë ê¹Œ? : ì˜ˆì¸¡
-> ëª¸ë¬´ê²Œê°€ ì–´ë–»ê²Œ ë ê¹Œ, ë‚´ì¼ ì˜¨ë„ëŠ” ì–´ë–¨ê¹Œ


ë¨¸ì‹ ëŸ¬ë‹ ì¤‘ì—ì„œ ì‚¬ëŒì˜ ë‡Œë¥¼ ëª¨ë°© : ë”¥ëŸ¬ë‹.

-------------- 0329
ë”¥ëŸ¬ë‹ :: ì‹œëƒ…ìŠ¤(ì—°ê²°ë¶€ìœ„, ì‹ ê²½ë§)ì˜ êµ¬í˜„.
â˜…ì‹œëƒ…ìŠ¤ì—ì„œ ì‹ ê²½ì „ë‹¬ë¬¼ì§ˆ(ë‹¨ë°±ì§ˆ)ì´ ìˆ˜ìš©ì²´ë¡œ ì´ë™, ë¬¼ì§ˆì´ ë§ì´ ë‚˜ì˜¬ ìˆ˜ë¡ ì „ë‹¬ë˜ëŠ” ì „ê¸°ì‹ í˜¸ê°€ ê°•í•´ì§„ë‹¤.
ë‡ŒëŠ” ì‹ í˜¸ê°€ ë°œìƒ or Xë¡œë§Œ êµ¬ë¶„.
ì‹ í˜¸ * ì‹ ê²½ì „ë‹¬ë¬¼ì§ˆì˜ ì–‘ = ì „ê¸°ì‹ í˜¸ -> íŠ¹ì • ë ˆë²¨ ì´ìƒì¼ ë•Œë§Œ ë°œìƒ íŒì • -> ì‹ ê²½ì„¸í¬ í•µì—ì„œ ì „ê¸°ì‹ í˜¸ í•©ì¹˜ê¸°
ì‹ ê²½ì „ë‹¬ë¬¼ì§ˆì˜ ì„¤ì •ì— ë”°ë¼ ì „ê¸°ì‹ í˜¸ê°€ ë‹¤ë¥´ê²Œ ë°œìƒ. ê±·ëŠ” ìš©ë„, ê¸°ì–µí•˜ëŠ” ìš©ë„ ë“±

---------------- 0330
ì‹ í˜¸ -> ì‹ ê²½ì „ë‹¬ë¬¼ì§ˆ -> ë¬¼ì§ˆì´ ìˆ˜ìš©ì²´ë¡œ ì´ë™ -> ë°˜ëŒ€í¸ ë‰´ëŸ° ìê·¹ -> ì‹ ê²½ì „ë‹¬ë¬¼ì§ˆì„ ì›ë˜ ìë¦¬ íšŒìˆ˜ -> ë°˜ë³µ

ë‡Œ ë¬¸ì œ :
ì‹œëƒ…ìŠ¤ ì‘ë™ X -> ë§ˆë¹„, ì¹˜ë§¤ ë“±
= ì‹œëƒ…ìŠ¤ ì„¤ì • X, ì‹ ê²½ì „ë‹¬ë¬¼ì§ˆì˜ ì–‘ ì œëŒ€ë¡œ ì„¤ì • X
-> ë”¥ëŸ¬ë‹ì€ ì‹ ê²½ì „ë‹¬ë¬¼ì§ˆì˜ ì–‘ì„ ë°”ê¾¸ëŠ” í”„ë¡œê·¸ë˜ë°.

ìŠµê´€ ë°”ê¾¸ê¸°? :
ë¶€ì •ì  ì´ë¯¸ì§€ ì‹¬ê¸°. ê³ í†µ ì£¼ì…. -> ì‹ ê²½ì „ë‹¬ë¬¼ì§ˆì˜ ì–‘ ë³€í™”ë¡œ ê¸°ì–µí•˜ê¸°.
= ë‡Œë‚´ í•™ìŠµì˜ ì›ë¦¬? : í–‰ë³µì€ ëŠ˜ë¦¬ê³  ê³ í†µì€ ì¤„ì´ëŠ” ë°©í–¥ìœ¼ë¡œ.

ê·¸ë¦¼ì±… : ì…ë ¥ì„ ì£¼ê³  ì •ë‹µì„ ì•Œë ¤ì¤€ë‹¤. -> í•™ìŠµìœ¼ë¡œ ì‹ ê²½ì „ë‹¬ë¬¼ì§ˆ ì„¤ì •í•˜ê¸°.
gil.fit(<ê·¸ë¦¼>, 'ì˜¤ë¦¬')


ë‰´ëŸ°ì˜ ë™ì‘(ì¶œë ¥) ::
ì‹ ê²½ì„¸í¬ê°€ ë‹¨ í•˜ë‚˜ë¼ ê°€ì •. (w=1)
ì‹ ê²½ì„¸í¬ ì¶œë ¥ h = ì…ë ¥ x * ì—°ê²°ê°•ë„(ì‹ ê²½ì „ë‹¬ë¬¼ì§ˆ ì–‘ : ë‹¨ì ˆ/ì•½/ê°•) w
w=1ì¸ ë‰´ëŸ° : h = 1x

â˜…í•™ìŠµì´ë€? :
ì‹ ê²½ì „ë‹¬ë¬¼ì§ˆì˜ ì–‘(w)ì„ ì¡°ì ˆí•˜ëŠ” ê²ƒ.

ex)
1ì‹œê°„(x) ê³µë¶€í•˜ë©´ 1ì‹œê°„(ground truth) ê²Œì„.
ê·¸ëŸ¼ 4ì‹œê°„ ê³µë¶€ì— ëª‡ ì‹œê°„ ê²Œì„í•  ìˆ˜ ìˆì„ì§€(prediction) wê°’ êµ¬í•˜ê¸°.
h = w * x(=1)
ì…ë ¥ê³¼ ì •ë‹µì´ ì •í•´ì¡Œë‹¤ë©´ ê°•ë„ì˜ ë³€í™”ì— ë”°ë¼ ì˜¤ì°¨ë¥¼ ì°¾ì•„ë‚´(ì•¼ë‹¨) ì¤„ì—¬ë‚˜ê°„ë‹¤.

ì‹¤ì œë¡œëŠ” ì—¬ëŸ¬ ê°œì˜ ì…ë ¥. ì…ë ¥ì˜ ìˆ˜ë§Œí¼ ì—°ê²°ë„ ì¡´ì¬.
-> ê° ì…ë ¥ë§ˆë‹¤ ì‹œëƒ…ìŠ¤ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê³±í•œ ë’¤ ëª¨ë‘ ë”í•œë‹¤. (weighted sum)

ë‰´ëŸ°ì€ weighted sumì´ ì¼ì • ê°’ ì´ìƒì¼ ë•Œë§Œ ì‹ í˜¸ ë°œìƒ. (ê³„ë‹¨ í•¨ìˆ˜)
= íŠ¹ì • ê°’(T) ì´ìƒì´ë©´ ON(1), ì•„ë‹ˆë©´ OFF(0)
ì‹ ê²½ì„¸í¬ í•µì—ì„œ weighted sum & ê³„ë‹¨ í•¨ìˆ˜ ì—­í• .

â˜…ì‹œí—˜ : ë‰´ëŸ° ê·¸ë¦¬ê¸°.
h = 1x
h = x1 + 2x2 + x3 + 3x4
h = 1 (if x1 + 2x2 + x3 + 3x4 > T) / 0 (otherwise)

-------------- 0405
ì•„ê¸°ê°€ ë¶ˆì„ ë§Œì ¸ë„ ë–¼ì§€ ëª»í•˜ëŠ” ì´ìœ ?
: ì‹œëƒ…ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ì„œ ë‰´ëŸ° ê°„ì— ê³ í†µ -> íšŒí”¼ êµ¬ì„±ì´ ì—†ìŒ.
ë‰´ëŸ°ì˜ ì¶œë ¥ = ëŒ€ë‹µ.


[ì„ í˜•íšŒê·€]
íšŒê·€(regression) :
ìì—°ì˜ ë²•ì¹™, í˜„ìƒ. ê·¸ì— ë”°ë¥¸ ì˜ˆì¸¡ì´ ê°€ëŠ¥.
ex) ì—°ì–´, ì—°ë ¹ê³¼ í˜ì˜ ê´€ê³„

ì„ í˜•íšŒê·€ :
ë¹„ë¡€ ê´€ê³„ì˜ íšŒê·€. ì„ í˜•íšŒê·€ë¥¼ ëª¨ì•„ì„œ ë¹„ì„ í˜• ì˜ˆì¸¡ ê°€ëŠ¥.
-> íšŒê·€ í˜•íƒœê°€ ë¹„ì„ í˜•ì´ì–´ë„ ì„ í˜•íšŒê·€ë¼ í•  ìˆ˜ ìˆë‹¤.
ex) ì§‘ì˜ í¬ê¸°-ê°€ê²©ì˜ ì§ì„  ê·¸ë˜í”„
xê°€ ì–´ë– í•œ ì„ í˜•ê²°í•© ìƒíƒœì¸ì§€.
yì¶•(ê°€ê²©) : ë‰´ëŸ°ì´ ë§ì¶°ì•¼ í•  ì •ë‹µ, ê·¸ë¥¼ ê²°ì •í•˜ëŠ” íŒ©í„°ë“¤ì´ ë§ë‹¤. í•™êµ°, í˜ì˜¤ì‹œì„¤...

---------------- 0406
https://www.desmos.com/	ê·¸ë˜í”„ ê·¸ë¦¬ê¸°.
csv : ì»´ë§ˆë¡œ êµ¬ë¶„ëœ, í•™ìŠµí•  ë°ì´í„°ê°€ ìˆëŠ” íŒŒì¼

ex) ì—°ê²°ê°•ë„ w ì°¾ê¸°.
ì¸ìŠ¤í„´ìŠ¤ (1,1),(2,2),(3,3) ë³´ê³  h=1x ìœ ì¶”í•´ë‚´ë©´ ì •í™•.
ë§Œì•½ w=2? -> ì˜¤ë¥˜. -> ìˆ˜ì • ìš”ì²­í•˜ë©´ í•™ìŠµ, ë§ì„ ë•Œê¹Œì§€

ê²½í—˜ì´ë€? : ë‹¤ì–‘í•œ ê²½ìš°ë¥¼ csvë¡œ ì €ì¥í•œë‹¤.
ì…ë ¥ì´ 2ê°œë©´ 3ì°¨ì› ê·¸ë˜í”„. ê·¸ ì´ìƒì€ X

h = wx + b
í•˜ë‚˜ì˜ ë‰´ëŸ°ì€ í•˜ë‚˜ì˜ ì„ í˜•íšŒê·€ë¥¼ í‘œí˜„. ì§ì„ ì´ íšŒê·€.
h : ê°€ì„¤, ë‰´ëŸ°ì˜ ëŒ€ë‹µ
ì—°ê²°ê°•ë„ w, ë°”ì´ì–´ìŠ¤ b : ì‹œëƒ…ìŠ¤ ì—°ê²°ê°•ë„ì˜ ê°’. ë‹¤ì–‘í•œ íšŒê·€ í‘œí˜„ ê°€ëŠ¥.
-> â˜…wì™€ bë¥¼ ì–´ë–»ê²Œ ì¡°ì ˆ? : ë‰´ëŸ°ì´ ì •ë‹µì„ ë” ì˜ ëŒ€ë‹µí•˜ë„ë¡ ì¡°ì ˆí•˜ê¸°.

â˜…â˜…ê·¸ë˜í”„ ëª¨ì–‘ì˜ ìœ ë˜ ì„¤ëª…í•˜ê¸°.
ë‰´ëŸ°ì´ ë§ëŠ” ëŒ€ë‹µì„ í•˜ëŠ”ì§€ ì•„ëŠ” ë°©ë²•? :
hì™€ ê¸°ì¡´ì˜ ì •ë‹µ(ground truth) yì˜ ì˜¤ì°¨ë¥¼ ê³„ì‚°.
â˜…ì°¨ì´ëŠ” ê°„ê²©ì´ë¯€ë¡œ ìŒìˆ˜ê°€ ë‚˜ì§€ ì•ŠëŠ”ë‹¤. -> ì ˆëŒ€ê°’.
-> â˜…ì˜¤ë¥˜ E = |xw - y| (xì¶•: w, yì¶•: E)
-> â˜…í•™ìŠµì´ë€? : ì˜¤ë¥˜(E)ê°€ ê±°ì˜ ì—†ë„ë¡ wë¥¼ ì¡°ì ˆí•˜ëŠ” ê²ƒ.

ê°€ì„¤(h) : ì–´ë–¤ í˜„ìƒì„ ì„¤ëª…, í‘œí˜„í•œ ê²ƒ. ì¦ëª…ë˜ì§€ ì•Šì•˜ì§€ë§Œ ì‹¤í—˜ê³¼ ì¡°ì ˆë¡œ ê²€ì¦í•  ìˆ˜ ìˆëŠ” ê²ƒ.

ex)
E = |w*1 - 1| í•™ìŠµ ë°ì´í„°? -> 1,1
csv (1,1)(2,2)(3,3) ì˜¤ë¥˜ê°’? -> E = |w*1 - 1| + |w*2 - 2| + |w*3 - 3|
E = |w*1 - 0.5| í•™ìŠµ ì™„ë£Œ? -> w=0.5
E = |w*1 - 3| í•™ìŠµ ì™„ë£Œ ê·¸ë˜í”„? -> h=3x

ì§€ë„í•™ìŠµ : ì…ë ¥ê³¼ ì •ë‹µì„ ì•Œë ¤ì£¼ë©´ì„œ í•™ìŠµí•œë‹¤.


ìœ„ì— ë‚˜ì˜¨ ì ˆëŒ€ê°’ ì˜¤ë¥˜ í•¨ìˆ˜ëŠ” Vì í˜•íƒœ, ì˜¤ë¥˜ ì¤„ë„ë¡ w ì¡°ì ˆí•˜ë ¤ë©´?
-> ê²½ì‚¬í•˜ê°•. : ê¸°ìš¸ê¸°ë¥¼ ì´ìš©í•´ ê³„ì† ê²½ì‚¬ ì•„ë˜ë¡œ ë‚´ë ¤ê°€ë©´ ì—ëŸ¬ê°€ ì—†ëŠ” ì§€ì ì— ë„ë‹¬í•  ê²ƒ.

ë‹¤ìŒ wê°’ ì¢Œí‘œ : w1 = w0 - a*ê¸°ìš¸ê¸° (a : ë°˜ì˜ ë¹„ìœ¨)
ex) w = 4 - 1*1 or w = -2 - 1*(-1)

------------- 0412
yungcheolbyun@gmail.com
ì ˆëŒ“ê°’ ì˜¤ë¥˜ í•¨ìˆ˜ì—ì„œ ë°–ìœ¼ë¡œ íŠ•ê²¨ë‚˜ê°ˆ ë•Œì˜ ìš©ì–´? í•™ìŠµë¥  ì˜¤ë²„ìŠˆíŒ….
ì˜¤ëŠ˜ ë‚´ë¡œ.

ì ˆëŒ€ê°’ ì˜¤ë¥˜ í•¨ìˆ˜ì˜ ê¸°ìš¸ê¸°ë¡œ wë¥¼ ê³ ì¹œë‹¤.
â˜…ê²½ì‚¬í•˜ê°• ìˆ˜ì‹ :
w = w - a*ê¸°ìš¸ê¸° (â˜…ê¸°ìš¸ê¸°ëŠ” wì§€ì ì—ì„œì˜ ê¸°ìš¸ê¸°.)
ex) E = |w - 1|
w=4 : w = 4 - 1*1 -> w=3
-> w=3 : w = 3 - 1*1 -> w=2
-> w=2 : w = 2 - 1*1 -> w=1

w=-2 : w = -2 - 1*(-1) -> w=-1 ~

if a(ë°˜ì˜ ë¹„ìœ¨) = 2?
w=-2 : w = -2 - 2*(-1) -> w=0
-> w=0 : w = 0 - 2*(-1) -> w=2
-> w=2 : w = 2 - 2*(1) -> w=0 ë¬´í•œ ë£¨í”„

ì ˆëŒ€ê°’ ì˜¤ë¥˜? :
1. ì™¼ìª½-ì˜¤ë¥¸ìª½ì€ í•­ìƒ ê°™ì€ ê¸°ìš¸ê¸° = í•­ìƒ ê°™ì€ ê²½ì‚¬í•˜ê°• ì†ë„.
2. wê°’ ì¡°ì ˆ ì‹¤íŒ¨ ê°€ëŠ¥
3. w=1ì¼ ë•Œ ê¸°ìš¸ê¸° êµ¬í•  ìˆ˜ ì—†ë‹¤.
-> ê¸°ìš¸ê¸°ë§Œ ë³´ê³  wê°’ ì§ì‘ ë¶ˆê°€.


ì œê³± ì˜¤ë¥˜ í•¨ìˆ˜ (square error func) :
E = |xw - y|^2
E=0ì— ê°€ê¹Œìš¸ ìˆ˜ë¡ ì—ëŸ¬ëŠ” ë” ì‘ì•„ì§„ë‹¤.
ex) 0.5*1=0.5, í•œí¸ 0.5*0.5=0.25

ë§ˆì°¬ê°€ì§€ë¡œ w ì§€ì ì˜ ê¸°ìš¸ê¸°ë§Œ êµ¬í•œë‹¤ë©´ ê²½ì‚¬í•˜ê°• ê°€ëŠ¥.
-> â˜…ë¯¸ë¶„ : xì¶• ë³€í™”ë¥¼ ì•„ì£¼ ì‘ê²Œ í•´ ì ‘ì„ ìœ¼ë¡œ ì •í™•í•œ ê¸°ìš¸ê¸° êµ¬í•˜ê¸°.
lim(âˆ†w->0)âˆ†E/âˆ†w = âˆ‚E/âˆ‚w
wë¥¼ ì•„ì£¼ ì¡°ê¸ˆ ëŠ˜ë ¸ì„ ë•Œ(âˆ‚w) EëŠ” ì–¼ë§ˆë‚˜ ëŠ˜ì–´ë‚ ê¹Œ.(âˆ‚E)
ë¸íƒ€ = ì°¨ì´

sinì„ ë¯¸ë¶„í•˜ë©´ cos

------------ 0413
ê¸°ìš¸ê¸° êµ¬í•˜ëŠ” í‘œí˜„ : lim(âˆ†w->0)âˆ†E/âˆ†w = âˆ‚E/âˆ‚w
ë¯¸ë¶„ ì—†ì´ë„ ê°€ëŠ¥, ë¹¼ëŠ” ì°¨ì´ê°€ ì‘ì•„ì•¼.
â˜…ê°œê°™ì€ ê·¸ë˜í”„ ì£¼ê³  ë¯¸ë¶„í•˜ë¼ê³  í•  ê°€ëŠ¥ì„±. ê¸°ìš¸ê¸° 0 ë¶€ë¶„ í™•ì¸. ì¦ê° ì†ë„ ê³ ë ¤.

â˜…ì—ëŸ¬ ê·¸ë˜í”„ì— ì œê³±ì„ í•œ ì´ìœ ? :
ì—ëŸ¬ ìµœì €ì ì„ ì°¾ì„ ë•Œ, ë©€ë¦¬ ìˆëŠ” ê°’ì˜ ê¸°ìš¸ê¸°ëŠ” ì»¤ì§€ê³  ê°€ê¹Œìš´ ê°’ì˜ ê¸°ìš¸ê¸°ëŠ” ê¸‰ê²©íˆ ì‘ì•„ì ¸ ìµœì €ì ì— ê·¼ì ‘í•˜ê¸° ì‰¬ì›Œì§„ë‹¤.
+ ëª¨ë“  ì§€ì ì—ì„œ ê¸°ìš¸ê¸° ê³„ì‚° ê°€ëŠ¥.
w ì§€ì ì˜ ê¸°ìš¸ê¸°ê°€ ë§¤ìš° í¬ë‹¤? : ìµœì €ì ì—ì„œ ë©€ë¦¬ ìˆë‹¤.
ë°˜ëŒ€ë¡œ ë§¤ìš° ì‘ë‹¤? : ìµœì €ì  ê·¼ì²˜ì— ìˆë‹¤.
ìŒì‹ì˜ ê°„ ë§ì¶”ê¸°, ì£¼ì°¨, ~

ì§€ë„í•™ìŠµ : ì…ë ¥ê³¼ ì •ë‹µì„ ì•Œë ¤ì£¼ë©´ì„œ í•™ìŠµí•œë‹¤.

í‰ê·  ì œê³± ì˜¤ë¥˜ í•¨ìˆ˜(MSE) : ì˜¤ì°¨ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì²™ë„
E = 1/3 * ((w*1 - 1)^2 + (w*2 - 2)^2 + (w*3 - 3)^2)
-> E = 1/N * Nâˆ‘{i=1}(wxi - yi)^2 [Nê°œ ë°ì´í„°]

https://gooopy.tistory.com/68
â˜…ì—í­(epoch) :
ëª¨ë“  ë°ì´í„°ë¥¼ í•œ ë²ˆì”© í•™ìŠµí•œ íšŸìˆ˜, ë„ˆë¬´ ë§ìœ¼ë©´ ì˜¤ë²„í”¼íŒ….
â˜…ë°°ì¹˜ ì‚¬ì´ì¦ˆ(batch size) :
ì—°ì‚° í•œ ë²ˆì— ë“¤ì–´ê°€ëŠ” ë°ì´í„° í¬ê¸°.

ì œê³± í•¨ìˆ˜ ë“±ìœ¼ë¡œ ì¸í•´ í•™ìŠµëŸ‰ ë„ˆë¬´ ë§ì„ ë•Œ : í¬ê²Œ ë¬¶ì–´ ì •ê·œí™”í•œ ê°’ë“¤ ì—¬ëŸ¬ ê°œë¡œ íŒë‹¨
-> ì € ë‘˜ì„ ì ë‹¹íˆ ì¡°ì ˆí•´ì•¼ ìµœì ì˜ ì†ë„ë¡œ êµ¬í•  ìˆ˜ ìˆë‹¤.

ê¸°ìš¸ê¸°ê°€ í¬ë‹¤?(âˆ†E/âˆ†w) :
w ì¡°ì ˆí•˜ë©´ Eê°€ í¬ê²Œ ë³€í™” -> w ë³€í™”ê°€ Eì— ë¯¸ì¹˜ëŠ” ì˜í–¥ í¬ë‹¤.
ê¸°ìš¸ê¸°ê°€ ì‘ë‹¤? :
w ì¡°ì ˆí•˜ë©´ Eê°€ ì‘ê²Œ ë³€í™” -> w ë³€í™”ê°€ Eì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ì‘ë‹¤.

ex) ë¯¸ì¹˜ëŠ” ì˜í–¥ êµ¬í•˜ê¸°.
E = (wx - y)^2ì—ì„œ ë°ì´í„° (1,1) ì£¼ì–´ì§ˆ ë•Œ, w=3 ì§€ì ì—ì„œ w ë³€í™”ê°€ Eì— ë¯¸ì¹˜ëŠ” ì˜í–¥?
1) ì‘ì€ ì°¨ì´ ëŒ€ì… 2) w ê¸°ì¤€ ë¯¸ë¶„

https://github.com/yungbyun/myml/blob/master/n01_simple.py
êµ¬ê¸€ ì½”ë© ì‹¤í–‰, plt ì¶”ê°€
â˜…ì½”ë“œ fit ì—­í•  : ì—í­ íšŸìˆ˜ë§Œí¼ í•™ìŠµì‹œí‚¤ê¸°.

=ì¤‘ê°„ : 26ì¼ ì˜¤í›„ 3ì‹œì¯¤=

--------------- 0419
í•™ìŠµë°©ë²•(w ì—…ë°ì´íŠ¸) :
ì‹œëƒ…ìŠ¤ ì—°ê²°ê°•ë„(w)ë¥¼ ë‚œìˆ˜ ì´ˆê¸°í™” (w=4)
-> w ì§€ì ì—ì„œ ì˜¤ë¥˜ ê·¸ë˜í”„ì˜ ê¸°ìš¸ê¸° êµ¬í•˜ê¸°
-> ê¸°ìš¸ê¸°ë¡œ w ë¹¼ê¸° (ê²½ì‚¬í•˜ê°•)
w = w - a*ê¸°ìš¸ê¸°

í…ì„œ :
ë¬´ì–¸ê°€ë¥¼ ì¡ì•„ë‹¹ê¸¸ ë•Œ ê·¸ ì£¼ìœ„ì˜ ë³µì¡í•œ ë³€í˜•.
ê²½ì‚¬ê°€ í° ìª½ìœ¼ë¡œ í˜ëŸ¬ê°„ë‹¤. ê³„ê³¡ì²˜ëŸ¼.
-> wê°€ ë§ì„ ìˆ˜ë¡ ëª¨ë“  ê°’ì— ëŒ€í•œ ë³µì¡í•œ ë³€í˜•.
í…ì„œí”Œë¡œìš° ë‚´ ìƒì„±ê°’(ë‚œìˆ˜), í…ì„œê°’ ë‹´ëŠ” ë°ì´í„°ì™€ í…ì„œ ì´ìš©í•œ ìˆ˜ì‹ ëª¨ë‘ í…ì„œë¡œ ê·œì •.
ex) w 2ê°œì™€ zì¶• ì—ëŸ¬ -> ê²½ì‚¬í•˜ê°• ì¤‘ì— ê¹Šì€ êµ¬ë©ì´ë¡œ ë“¤ì–´ê°€ë©´ wê°’ë“¤ í¬ê²Œ ë³€í™”

â˜…TFë¡œ ì„ í˜• íšŒê·€ í•™ìŠµ :
1. x=[1] 1ì‹œê°„ ì¼ì„ í•˜ë©´-
2. y=[1] 1ë§Œì›ì„ ì¤€ë‹¤.
3. w = tf.Variable(tf.random_normal([1])) ì—°ê²°ê°•ë„ ì„¤ì •
4. h = w * x ì‹ ê²½ ì„¸í¬ì˜ ì¶œë ¥ê°’?
5. E = (h - y)^2 ì—ëŸ¬í•¨ìˆ˜ ìƒì„±
6. ê²½ì‚¬í•˜ê°•ìœ¼ë¡œ ìµœì í™” : train ê°ì²´(ê²½ì‚¬í•˜ê°• ì‹¤í–‰), ì„¸ì…˜ ê°ì²´(train ë‹¤ë£¨ëŠ” ì—­í• )

train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(E)
sess = tf.Session()
sess.run(tf.global_variables_initializer()) #ğ‘¤ê°’ ì´ˆê¸°í™”
err_list = []
for i in range(101):
w_val = sess.run(w)
err = sess.run(E)
print(i, 'w:', w_val, 'cost:', err)
err_list.append(err)
â˜…sess.run(train) #ì´ í•¨ìˆ˜ì˜ ì—­í• ? : train í˜¸ì¶œí•´ ê²½ì‚¬í•˜ê°• 1ë²ˆ

7. í•™ìŠµì´ ëë‚˜ê³  í…ŒìŠ¤íŠ¸
8. ì—ëŸ¬ ê·¸ë˜í”„



0427 ì¤‘ê°„ ë ---------------
í…ì„œì˜ íŒŒìƒë„ í…ì„œ.
for i in range(101):
	print(sess.run(w), sess.run(E))
	sess.run(train)
ì—í­ 101ë²ˆ = ê²½ì‚¬í•˜ê°• 101ë²ˆ

í…ì„œ h=wx ì²˜ìŒ ë§Œë“¤ ë•Œ ì ìš©í•œ xê°’ì´ ê·¸ëŒ€ë¡œ ì‚¬ìš© -> ì›í•˜ëŠ” ê°’ ë„£ëŠ” ë°©ë²•?
= ìë¦¬í‘œì‹œê¸°.(placeholder)

w = tf.Variable(tf.random_normal([1]))
hypo = w * X
cost = (hypo  - Y) ** 2
~
print(sess.run(w), sess.run(cost, feed_dict={X:x_data, Y:y_data}))
~
print(sess.run(hypo, feed_dict={X:[3, 5, 7, 8, 10]}))
Xì— x_dataë¥¼, Yì— y_dataë¥¼ ì‚½ì…í•œë‹¤.

â˜…í…ì„œí”Œë¡œì˜ ì˜¤ë¥˜ ê³„ì‚° ê·¸ë˜í”„ ::
ğ‘¤ì˜ ë³€í™”ê°€ ğ¸ì— ë¯¸ì¹˜ëŠ” ì˜í–¥(ê¸°ìš¸ê¸°)ì„ êµ¬í•œ í›„ ê²½ì‚¬í•˜ê°•í•˜ë„ë¡ ğ‘¤ë¥¼ ì¡°ì ˆ
ê³±í•˜ê¸°ì—ì„œ ì˜†ì˜ ê°’ = í° ê°’ì— ë¯¸ì¹˜ëŠ” ì˜í–¥.

--------------- 0503
ë…¼ë¬¸ì˜ ëª¨ë“ˆí™”. ë‚´ì¼ íœ´ê°•.
ê³¼ì œ : sigmoid ê·¸ë˜í”„ì˜ ê¸°ì›ê³¼ ìš©ë„ ì¡°ì‚¬, ë¯¸ë¶„ í˜„í™©? ë°˜ì¥ ë¶„ëŸ‰

ë¡œì§€ìŠ¤í‹± íšŒê·€ ::
ì¡°ê±´ ë³€ê²½ - ëª‡ ì‹œê°„ì„ ê³µë¶€í•´ë„ ë…¸ëŠ” ì‹œê°„ì€ 1ì‹œê°„, ì•„ë‹ˆë©´ ì—†ìŒ.
ì„ í˜• íšŒê·€(h=wx)ë¡œëŠ” ë¹„ì„ í˜•ì  êµ¬ì¡°ë¥¼ í•™ìŠµí•  ìˆ˜ ì—†ë‹¤.
-> ê¸°ì¡´ì— ì£¼ì–´ì§„ ê·¸ë˜í”„ë¥¼ ì ìš©ì‹œí‚¤ê¸°. h=1/(1+e^-wx)
â˜…sigmoid ê·¸ë˜í”„ì—ì„œì˜ ê²°ì •ê²½ê³„ xê°’? : xê°€ 0ì´ ë˜ì–´ì•¼.

ë‰´ëŸ° í•µì—ì„  ì´ë¯¸ sigmoidì˜ ì‘ìš©ì„ í•˜ê³  ìˆë‹¤.
â˜…ë‰´ëŸ° ê·¸ë¦¼ë§Œìœ¼ë¡œ ê²°ì •ê²½ê³„ êµ¬í•˜ê¸°.

hê°€ sigmoidë¡œ ë³€í™”í•œ ë’¤ ì—ëŸ¬í•¨ìˆ˜ ì ìš© ê°€ëŠ¥? -> ë¶ˆê°€. ìƒˆ í•¨ìˆ˜ í•„ìš”.

--------------- 0511
train ê°ì²´ì˜ ì—í­ ì§„í–‰ê³¼ ì—­ì „íŒŒ

ì‹œê·¸ëª¨ì´ë“œê°€ ë¯¸ì¹˜ëŠ” ì˜í–¥(ë¯¸ë¶„) : sig'(x) = sig(x)*(1-sig(x))
& ì‹œê·¸ëª¨ì´ë“œì˜ ê°’ì€ 0ê³¼ 1 ì‚¬ì´.
-> sig'(x)ì˜ ê°’ì€ ë§¤ìš° ì‘ë‹¤. -> â˜… wì— ë¯¸ì¹˜ëŠ” ì˜í–¥ë„ ë§¤ìš° ì‘ë‹¤. (vanishing gradient)
-> í•™ìŠµì´ ì œëŒ€ë¡œ ì•ˆ ëœë‹¤. -> ì¸ê³µì§€ëŠ¥ ë©¸ë§, ë¨¸ì‹ ëŸ¬ë‹ì˜ ì‹œëŒ€.

ê²°ì •ê²½ê³„: wx+b=0
-> â˜… w, bë¥¼ ì—…ë°ì´íŠ¸(í•™ìŠµ)í•œë‹¤ëŠ” ì˜ë¯¸? : ë” ë‚˜ì€ ê²°ì •ê²½ê³„ë¥¼ ì°¾ëŠ” ê²ƒ.

reduce_mean : ê°ì¢… ë°ì´í„°ì˜ í‰ê·  êµ¬í•˜ê¸°. -> í•˜ë‚˜ì˜ ì—ëŸ¬ê°’ êµ¬í•´ ìˆ˜ì •.

--------------- 0517
ìŠ¤ë§ˆíŠ¸ê·¸ë¦¬ë“œ:
íƒœì–‘ê´‘ ë“± ë¶„ì‚°ì „ì›ìœ¼ë¡œ ì¸í•œ ê³¼ë‹¤í•œ ì „ë ¥ ì¡°ì ˆí•˜ëŠ” ë°©ë²•? -> VPP í”Œë«í¼ ê¸°ìˆ 
ê´‘ì—­ ì „ë ¥ë§ì˜ í•œê³„ -> ë§ˆì´í¬ë¡œê·¸ë¦¬ë“œ í”Œë«í¼
DR ê¸°ìˆ ë¡œ ì‹œê°„ëŒ€ ì „ê¸° ì‚¬ìš© í˜œíƒ ì£¼ë ¤ë©´ ì‚¬ìš©ëŸ‰ ì˜ˆì¸¡ í•„ìš”.

ì‹ ê²½ ì„¸í¬ì— ì…ë ¥ ì¶”ê°€:
ì…ë ¥ 2ê°œ ë˜ë©´ OR íŒì • -> ì¡°ê±´ í•˜ë‚˜ë§Œ ë§Œì¡±í•´ë„ 1, ì•„ë‹ˆë©´ 0
-> ê²°ì •ê²½ê³„ w1x1 + w2x2 + b = 0
OR ë¿ë§Œ ì•„ë‹ˆë¼ NAND ë“± ì‚¬ìš©. (ëª¨ë“  ë””ë°”ì´ìŠ¤ êµ¬í˜„ ê°€ëŠ¥)


https://github.com/mxstbr/login-flow
https://kimyang-sun.tistory.com/entry/%EB%A6%AC%EC%95%A1%ED%8A%B8-%EB%A6%AC%EB%8D%95%EC%8A%A4-%ED%88%B4%ED%82%B7-%EB%A6%AC%EB%8D%95%EC%8A%A4-%EC%82%AC%EA%B0%80-React-Redux-Toolkit-Redux-Saga-TypeScript-Nextjs
https://hojung-testbench.tistory.com/42


